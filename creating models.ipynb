{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação dos modelos\n",
    "Nesse notebook, utilizamos os dados obtidos a partir de webscraping para treinar os nossos modelos de NLP. Para treiná-los, utlizamos o método de Lidstone como técnica de *smoothing*, e como possuíamos poucos dados, treinamos os modelos com uni-gramas apenas. \n",
    "\n",
    "Obs.: Esse notebook presta apenas um serviço didático, já que os dados obtidos com webscraping estão faltantes. Eles não se encontram junto do trabalho final pois não investigamos sobre os direitos de distribuição dos dados. Se o leitor estiver interessado, poderá facilmente obter os dados na internet ou substituí-los por algum texto de sua escolha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities in general\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# nltk models to be tested\n",
    "from nltk.lm import Lidstone\n",
    "\n",
    "# nltk utilities\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imporing the files\n",
    "PASTA = 'legenda'\n",
    "one_per_line = True\n",
    "PATH = f'{PASTA}/*.txt'\n",
    "files = glob.glob(PATH)\n",
    "\n",
    "# for one phrase per line\n",
    "if one_per_line:\n",
    "    full_texts = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            text = f.readlines()\n",
    "            # tokenizing the text\n",
    "            tokens = [word_tokenize(tweet) for tweet in text]\n",
    "        full_texts += tokens\n",
    "else:\n",
    "    full_texts = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            text = text.replace('\\n\\n', '.')\n",
    "            text = text.replace('\\n', ' ')\n",
    "            text = text.split('.')\n",
    "            text = [phrase+'.' for phrase in text]\n",
    "            # tokenizing the text\n",
    "            tokens = [word_tokenize(paragraph) for paragraph in text]\n",
    "        full_texts += tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lidstone(0.1, 1)\n",
    "ngrams, vocab = padded_everygram_pipeline(1, full_texts)\n",
    "model.fit(ngrams, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.05914908336214\n",
      "que se não Tirar os homens - essa Você ... Tudo se o é legal salvador foi que diferentes de Estou , a temos ? quer uma outro aí Onde ter . sente `` não mas dormiria Nick presentes ? você . mais sentir Enviaremos A . a Ela nunca\n"
     ]
    }
   ],
   "source": [
    "print(model.perplexity([[\"e\"]]))\n",
    "print(*model.generate(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *How to pickle and load models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling the model\n",
    "pickle.dump(model, open(f'models/{PASTA}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "a = pickle.load(open('models/test.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fd5bd47164d17c72c7ae2be81e996040e07432327c3ca0031f27ead335683c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
